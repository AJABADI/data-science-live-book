Introduction
===

### What is this about?

In practice, 90% of the time is spent in data preparation this book</a> does't have -yet- empirical information about how model performance increases by preparing the data.

```{r ,results="hide", echo=FALSE}
library(knitr)
opts_knit$set(base.dir = "data_preparation")
```

<style type="text/css">
.table {
    width: 40%;
}
</style>

#### Remove outliers 

Yes, model deals with this, but some noise will affect results anyway. 
If we need to report the variables used in the model, we'll end up removing outliers to not see an histogram with only one bar, and/or show not a biased mean. 
It's better to show a non-biased number than justifying the model "will handle" extreme values.

<br>

#### Don't use information from the future

<img src="back_to_the_future.png" width='250px'> 

Common mistake when starting a new predictive model project, for example:

Imagine we need to build a predictive model to know what users are likely to adquire full subscription in a web application, and this software has a ficticious feature called it `Feature A`:


```{r echo=FALSE}
d1=data.frame(user_id=rep(1:10), 
              feature_A=c("yes","yes","yes","no","yes","no","no","no","no","no"),
              full_subscription=c("yes","yes","yes","no","yes","no","no","no","no","no")) 
knitr::kable(d1, digits = 2)
```


We build the predictive model, we got a perfect accuracy, and an inspection throws the following: _"100% of users that have full subscription, uses Feature A"_. Some predictive algorithms report variable importance, thus `feature_A` will be at the top.

**The problem is:** `feature_A` is only availble **after the user pays** the full subcription. It cannot be used.

**The key message is**: Don't trust in perfect variables, nor perfect models. 

<br>

#### Play fair with data, let it to develop their behavior

If a **numerical variable** increases as time moves -for example the quantity of pages visit-, we may need to define an **observation time window** to analyze data in order to not bias data input. That is:

**Selecting the minimun time:**

In using a web application it may be time since user creation, in drug analysis it could be the time since the patient took the medicine.

**Selecting the maximun time**

It's not the same to get an user with 50 page views in 3 months since signup, than 50 page views in 3 days. Here the average page views since creation may help.

Don't defining a maximun, we may lead to think that a user is each day more likely to adqcuiere full subscription since he is acumulating 'page views'. In this point the average time to get full may be useful, if this value is 4 months, we could add 2 more months as a 'bonus time' and then **excluding all the user behavior** after the 6th month to create the model.


TODO: add plot containing 2 vertical lines explaning the min and max date.
------


 then extracting conslusions like: "Likelihood of adcquiere full subscription increases as page visits increases" may be **biassed**.

The higher the page views, the higher the likelihood of getting full subscription. However we should define a time window to analyze data. 

<br>





